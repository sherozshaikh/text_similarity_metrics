{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## üìù Textual Similarity Assessment Suite\n",
        "\n",
        "Textual Similarity Assessment Suite is a Python class designed for computing various text similarity metrics between elements in pandas dataframe. It supports a wide range of metrics and provides functionalities for preprocessing, computing similarity scores, and exporting results.\n",
        "\n",
        "### Overview\n",
        "\n",
        "Welcome to the Textual Similarity Assessment Suite repository! This project provides a robust toolkit for evaluating and comparing text similarity using advanced Natural Language Processing (NLP) techniques. It enables users to compute a variety of similarity metrics between textual elements extracted from datasets, facilitating detailed analysis and assessment of text similarity.\n",
        "\n",
        "This suite supports a wide range of functionalities, including preprocessing of text for normalization, and computation of metrics such as Jaccard similarity, Levenshtein distance, Dice coefficient, and more. Users can customize metric selection, analyze results, and export findings in CSV and ZIP formats for further insights and applications.\n",
        "\n",
        "Explore the capabilities of the Textual Similarity Assessment Suite to enhance your text analysis workflows and gain deeper insights into textual similarity relationships.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ú® Key Features\n",
        "\n",
        "- Compute similarity metrics such as Jaccard similarity, Levenshtein distance, Dice coefficient, and more.\n",
        "- Flexible metric selection and output customization.\n",
        "- Preprocessing utilities for text normalization and character trimming.\n",
        "- Export results to CSV and ZIP formats.\n",
        "\n",
        "---\n",
        "\n",
        "### üì¶ Requirements\n",
        "\n",
        "- Python 3.x\n",
        "- pandas\n",
        "- nltk\n",
        "- jellyfish\n",
        "- fuzzywuzzy\n",
        "- numpy\n",
        "- scipy\n",
        "- pandarallel (optional for parallel processing)\n",
        "\n",
        "---\n",
        "\n",
        "### üíª Installation\n",
        "\n",
        "```bash\n",
        "pip install --quiet numpy pandas fuzzywuzzy jellyfish python-Levenshtein pandarallel\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ Usage\n",
        "\n",
        "#### Using `text_scoring.py`\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from text_scoring import TextScoring\n",
        "\n",
        "# Example usage with DataFrame\n",
        "df = pd.read_csv('test_df.csv')\n",
        "\n",
        "# Create an instance of TextScoring and perform similarity scoring on the DataFrame\n",
        "TextScoring(\n",
        "    dataframe_object=df,\n",
        "    output_folder='Example1',\n",
        "    col_name_1='PROD_DESC',\n",
        "    col_name_2='KEYWORD',\n",
        "    metrics_list=['all']\n",
        ").main()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from text_scoring import TextScoring\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame(data={\n",
        "    'doc1_elements': ['apple', 'banana', 'cherry'],\n",
        "    'doc2_elements': ['apples', 'bannnana', 'charries']\n",
        "})\n",
        "\n",
        "# Create TextScoring instance and compute similarity scores\n",
        "TextScoring(\n",
        "    dataframe_object=df,\n",
        "    output_folder='Example2',\n",
        "    col_name_1='doc1_elements',\n",
        "    col_name_2='doc2_elements',\n",
        "    # edit_distance is incorrect and will be ignored. the correct name is editdistance\n",
        "    metrics_list=['basic_jaccard_similarity','dice_coefficient','edit_distance',],\n",
        ").main()\n",
        "```"
      ],
      "metadata": {
        "id": "-bfMWe597Zdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# Checks for required Python packages and installs them if not already installed.\n",
        "!pip install --quiet importlib\n",
        "import importlib\n",
        "\n",
        "req_packages:list = ['typing','numpy','pandas','re','os','shutil','zlib','collections','warnings','difflib','fuzzywuzzy','jellyfish','python-Levenshtein','scipy','nltk','pandarallel']\n",
        "\n",
        "for package_name in req_packages:\n",
        "  try:\n",
        "    importlib.import_module(package_name)\n",
        "  except:\n",
        "    try:\n",
        "      !pip install --quiet {package_name}\n",
        "    except Exception as e:\n",
        "      print(f\"Required package {package_name} was not installed!: {str(e)}\")\n",
        "del importlib\n",
        "print(\"All required packages are installed.\")\n",
        "\n",
        "# Import installed packages.\n",
        "import time\n",
        "from typing import List,Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import zlib\n",
        "from collections import Counter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from difflib import SequenceMatcher as difflib_sequencematcher\n",
        "from fuzzywuzzy import fuzz\n",
        "import jellyfish\n",
        "import Levenshtein\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "\n",
        "import nltk\n",
        "nltk.download(['punkt', 'stopwords'])\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import ngrams\n",
        "from nltk.metrics.distance import edit_distance\n",
        "\n",
        "from pandarallel import pandarallel\n",
        "pandarallel.initialize(progress_bar=True)\n",
        "print(\"All required packages are imported.\")\n",
        "\n",
        "class TextScoring():\n",
        "  \"\"\"\n",
        "  A class for computing text similarity metrics between elements in a pandas DataFrame.\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self,dataframe_object:pd.DataFrame,output_folder:str='Mapped_Attributes',col_name_1:str='doc1_elements',col_name_2:str='doc2_elements',metrics_list:list=['all']):\n",
        "    \"\"\"\n",
        "    Initialize the TextScoring class.\n",
        "\n",
        "    Args:\n",
        "    - dataframe_object (DataFrame): Pandas DataFrame object containing the data to process.\n",
        "    - output_folder (str, optional): Name of the output folder where results will be stored. Defaults to 'Mapped_Attributes'.\n",
        "    - col_name_1 (str, optional): Name of the column in the DataFrame representing document 1 elements. Defaults to 'doc1_elements'.\n",
        "    - col_name_2 (str, optional): Name of the column in the DataFrame representing document 2 elements. Defaults to 'doc2_elements'.\n",
        "    - metrics_list (list, optional): List of specific text scoring metrics to use. Defaults to ['all'].\n",
        "      Options for metrics:\n",
        "      - 'basic_jaccard_similarity': Basic Jaccard similarity coefficient.\n",
        "      - 'weighted_jaccard_similarity': Weighted Jaccard similarity coefficient.\n",
        "      - 'damerau_levenshtein_distance': Damerau-Levenshtein distance.\n",
        "      - 'dice_coefficient': Dice coefficient.\n",
        "      - 'sequencematcher': SequenceMatcher similarity.\n",
        "      - 'editdistance': Edit distance (Levenshtein distance).\n",
        "      - 'fuzz_partial_ratio': Partial ratio using fuzzy matching.\n",
        "      - 'fuzz_ratio': Ratio using fuzzy matching.\n",
        "      - 'fuzz_token_set_ratio': Token set ratio using fuzzy matching.\n",
        "      - 'fuzz_token_sort_ratio': Token sort ratio using fuzzy matching.\n",
        "      - 'fuzz_wratio': Weighted ratio using fuzzy matching.\n",
        "      - 'hamming_distance': Hamming distance.\n",
        "      - 'jaro_similarity': Jaro similarity.\n",
        "      - 'jaro_winkler_similarity': Jaro-Winkler similarity.\n",
        "      - 'jensen_shannon_divergence': Jensen-Shannon divergence.\n",
        "      - 'levenshtein_distance': Levenshtein distance.\n",
        "      - 'levenshtein_similarity': Levenshtein similarity.\n",
        "      - 'minhash_containment_distance': MinHash containment distance.\n",
        "      - 'monge_elkan_similarity': Monge-Elkan similarity.\n",
        "      - 'normalized_compression_distance': Normalized compression distance.\n",
        "      - 'overlap_coefficient': Overlap coefficient.\n",
        "      - 'ratcliff_obershelp_similarity': Ratcliff-Obershelp similarity.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    # Define text scoring metrics and corresponding methods\n",
        "    self.text_metrics:dict={\n",
        "      'get_basic_jaccard_similarity':self.get_basic_jaccard_similarity,\n",
        "      'get_weighted_jaccard_similarity':self.get_weighted_jaccard_similarity,\n",
        "      'get_damerau_levenshtein_distance':self.get_damerau_levenshtein_distance,\n",
        "      'get_dice_coefficient':self.get_dice_coefficient,\n",
        "      'get_difflib_sequencematcher':self.get_difflib_sequencematcher,\n",
        "      'get_editdistance':self.get_editdistance,\n",
        "      'get_fuzz_partial_ratio':self.get_fuzz_partial_ratio,\n",
        "      'get_fuzz_ratio':self.get_fuzz_ratio,\n",
        "      'get_fuzz_token_set_ratio':self.get_fuzz_token_set_ratio,\n",
        "      'get_fuzz_token_sort_ratio':self.get_fuzz_token_sort_ratio,\n",
        "      'get_fuzz_wratio':self.get_fuzz_wratio,\n",
        "      'get_hamming_distance':self.get_hamming_distance,\n",
        "      'get_jaro_similarity':self.get_jaro_similarity,\n",
        "      'get_jaro_winkler_similarity':self.get_jaro_winkler_similarity,\n",
        "      'get_jensen_shannon_divergence':self.get_jensen_shannon_divergence,\n",
        "      'get_levenshtein_distance':self.get_levenshtein_distance,\n",
        "      'get_levenshtein_similarity':self.get_levenshtein_similarity,\n",
        "      'get_minhash_containment_distance':self.get_minhash_containment_distance,\n",
        "      'get_monge_elkan_similarity':self.get_monge_elkan_similarity,\n",
        "      'get_normalized_compression_distance':self.get_normalized_compression_distance,\n",
        "      'get_overlap_coefficient':self.get_overlap_coefficient,\n",
        "      'get_ratcliff_obershelp_similarity':self.get_ratcliff_obershelp_similarity,\n",
        "    }\n",
        "\n",
        "    self.df1:pd.DataFrame = dataframe_object\n",
        "    self.output_folder:str = self.trim_characters(stxt=output_folder).replace(' ','_')\n",
        "    self.col_name_1:str = col_name_1\n",
        "    self.col_name_2:str = col_name_2\n",
        "\n",
        "    # Determine which scoring metrics to use based on metrics_list\n",
        "    self.scoring_metrics:dict = self.text_metrics if 'all' in metrics_list else {'get_'+str(k):self.text_metrics['get_'+str(k)] for k in metrics_list if ('get_'+str(k) in self.text_metrics.keys())}\n",
        "\n",
        "  def __repr__(self):\n",
        "    \"\"\"\n",
        "    Returns a string representation of the class instance.\n",
        "    \"\"\"\n",
        "    return f\"TextScoring()\"\n",
        "\n",
        "  def __str__(self):\n",
        "    \"\"\"\n",
        "    Returns a description of the class.\n",
        "    \"\"\"\n",
        "    return \"Class Similarity Score for Elements given in DataFrame\"\n",
        "\n",
        "  def get_jaro_winkler_similarity(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Calculates the Jaro-Winkler similarity between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: similarity score (percentage).\n",
        "    \"\"\"\n",
        "    return (jellyfish.jaro_winkler_similarity(sent_1,sent_2))*100\n",
        "\n",
        "  def get_minhash_containment_distance(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Calculates the MinHash containment distance between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: MinHash containment distance score.\n",
        "    \"\"\"\n",
        "    sent_1_len,sent_2_len,sent_1_2_len=len(sent_1),len(sent_2),len(set(sent_1).intersection(set(sent_2)))\n",
        "    if sent_1_len>sent_2_len:\n",
        "      return sent_1_2_len / sent_1_len\n",
        "    else:\n",
        "      return sent_1_2_len / sent_2_len\n",
        "\n",
        "  def get_difflib_sequencematcher(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the similarity ratio between two strings using difflib's SequenceMatcher.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Similarity ratio between the two strings, scaled to percentage (0 to 100).\n",
        "      The ratio measures how similar the sequences are, where 100 means identical.\n",
        "    \"\"\"\n",
        "    return difflib_sequencematcher(isjunk=None,autojunk=True,a=sent_1,b=sent_2).ratio()*100\n",
        "\n",
        "  def get_fuzz_ratio(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the fuzz ratio between two strings using Levenshtein Distance.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: similarity score\n",
        "    \"\"\"\n",
        "    return fuzz.ratio(sent_1,sent_2)\n",
        "\n",
        "  def get_fuzz_partial_ratio(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the partial fuzz ratio between two strings using partial matching.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: similarity score\n",
        "    \"\"\"\n",
        "    return fuzz.partial_ratio(sent_1,sent_2)\n",
        "\n",
        "  def get_fuzz_token_sort_ratio(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the fuzz ratio between two strings after sorting internal tokens.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: similarity score\n",
        "    \"\"\"\n",
        "    return fuzz.token_sort_ratio(sent_1,sent_2)\n",
        "\n",
        "  def get_fuzz_token_set_ratio(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the fuzz ratio between two strings using token sets.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: similarity score\n",
        "    \"\"\"\n",
        "    return fuzz.token_set_ratio(sent_1,sent_2)\n",
        "\n",
        "  def get_fuzz_wratio(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the WRatio between two strings using token sorting.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: similarity score\n",
        "    \"\"\"\n",
        "    return fuzz.WRatio(sent_1,sent_2)\n",
        "\n",
        "  def get_editdistance(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the Edit Distance between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: editdistance score\n",
        "    \"\"\"\n",
        "    return 1 - (edit_distance(s1=sent_1,s2=sent_2) / max(len(sent_1),len(sent_2)))\n",
        "\n",
        "  def get_basic_jaccard_similarity(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the basic Jaccard similarity coefficient between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Basic Jaccard similarity coefficient score.\n",
        "      The score is computed as the size of the intersection of the token sets\n",
        "      divided by the size of the union of the token sets.\n",
        "      Returns 0.0 if the union set size is zero.\n",
        "    \"\"\"\n",
        "    set_1:set = set(self.get_nltk_word_tokenize(txt=sent_1))\n",
        "    set_2:set = set(self.get_nltk_word_tokenize(txt=sent_2))\n",
        "    union_set:int = len(set_1.union(set_2))\n",
        "    return len(set_1.intersection(set_2)) / union_set if union_set > 0 else 0.0\n",
        "\n",
        "  def get_weighted_jaccard_similarity(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the weighted Jaccard similarity coefficient between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Weighted Jaccard similarity coefficient score.\n",
        "      The score is computed as the weighted sum of the intersection of token frequencies\n",
        "      divided by the weighted sum of the union of token frequencies.\n",
        "    \"\"\"\n",
        "    set_1:set = set(self.get_nltk_word_tokenize(txt=sent_1))\n",
        "    set_2:set = set(self.get_nltk_word_tokenize(txt=sent_2))\n",
        "    intersection_set:set = set_1.intersection(set_2)\n",
        "    union_set:set = set_1.union(set_2)\n",
        "    weighted_intersection:int = sum(min(sent_1.count(token),sent_2.count(token)) for token in intersection_set)\n",
        "    weighted_union:int = sum(max(sent_1.count(token),sent_2.count(token)) for token in union_set)\n",
        "    return weighted_intersection/weighted_union\n",
        "\n",
        "  def get_dice_coefficient(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the Dice coefficient between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Dice coefficient score.\n",
        "      The score is computed as twice the size of the intersection of the token sets\n",
        "      divided by the sum of the sizes of both token sets.\n",
        "    \"\"\"\n",
        "    set_1:set = set(self.get_nltk_word_tokenize(txt=sent_1))\n",
        "    set_2:set = set(self.get_nltk_word_tokenize(txt=sent_2))\n",
        "    intersection_set:int = len(set_1.intersection(set_2))\n",
        "    return (2.0 * intersection_set) / (len(set_1) + len(set_2))\n",
        "\n",
        "  def get_overlap_coefficient(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the overlap coefficient between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Overlap coefficient score.\n",
        "      The score is computed as the size of the intersection of the token sets\n",
        "      divided by the size of the smaller of the two token sets.\n",
        "    \"\"\"\n",
        "    set_1:set = set(self.get_nltk_word_tokenize(txt=sent_1))\n",
        "    set_2:set = set(self.get_nltk_word_tokenize(txt=sent_2))\n",
        "    intersection_set:int = len(set_1.intersection(set_2))\n",
        "    return intersection_set / min(len(set_1),len(set_2))\n",
        "\n",
        "  def get_levenshtein_distance(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the Levenshtein distance between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Levenshtein distance between the two strings.\n",
        "      The distance represents the minimum number of single-character edits\n",
        "      (insertions, deletions, substitutions) required to change one string into the other.\n",
        "    \"\"\"\n",
        "    return jellyfish.levenshtein_distance(sent_1,sent_2)\n",
        "\n",
        "  def get_damerau_levenshtein_distance(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the Damerau-Levenshtein distance between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Damerau-Levenshtein distance between the two strings.\n",
        "      The distance measures the minimum number of operations (insertions, deletions,\n",
        "      substitutions, and transpositions of adjacent characters) required to transform\n",
        "      one string into the other.\n",
        "    \"\"\"\n",
        "    return jellyfish.damerau_levenshtein_distance(sent_1,sent_2)\n",
        "\n",
        "  def get_hamming_distance(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the Hamming distance between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Hamming distance between the two strings.\n",
        "      The distance is the number of positions at which the corresponding characters\n",
        "      are different between the two strings. The strings must be of equal length.\n",
        "    \"\"\"\n",
        "    return jellyfish.hamming_distance(sent_1,sent_2)\n",
        "\n",
        "  def get_jaro_similarity(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the Jaro similarity between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Jaro similarity score between the two strings.\n",
        "      The score ranges from 0 (no similarity) to 1 (exact match),\n",
        "      measuring the similarity between the strings based on character matching.\n",
        "    \"\"\"\n",
        "    return jellyfish.jaro_similarity(sent_1,sent_2)\n",
        "\n",
        "  def get_levenshtein_similarity(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the normalized Levenshtein similarity between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Normalized Levenshtein similarity score between the two strings.\n",
        "      The score ranges from 0 (no similarity) to 1 (exact match),\n",
        "      computed as 1 - (Levenshtein distance / maximum length of the two strings).\n",
        "    \"\"\"\n",
        "    return 1 - (Levenshtein.distance(sent_1,sent_2) / max(len(sent_1),len(sent_2)))\n",
        "\n",
        "  def get_normalized_compression_distance(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the Normalized Compression Distance (NCD) between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Normalized Compression Distance (NCD) score between the two strings.\n",
        "      The score is computed as 1 - (compressed_combined - min(compressed_1, compressed_2)) /\n",
        "      max(compressed_1, compressed_2), where compressed lengths are obtained using zlib compression.\n",
        "      NCD measures the similarity between strings based on their compressed size,\n",
        "      normalized by the size of the smallest compressed string.\n",
        "    \"\"\"\n",
        "    combined_length:int = len(sent_1 + sent_2)\n",
        "    compressed_1:int = len(zlib.compress(sent_1.encode(encoding='utf-8',errors='replace')))\n",
        "    compressed_2:int = len(zlib.compress(sent_2.encode(encoding='utf-8',errors='replace')))\n",
        "    compressed_combined:int = len(zlib.compress((sent_1 + sent_2).encode(encoding='utf-8',errors='replace')))\n",
        "    ncd_score:float = (compressed_combined - min(compressed_1,compressed_2)) / max(compressed_1,compressed_2)\n",
        "    return 1 - ncd_score\n",
        "\n",
        "  def get_nltk_word_tokenize(self,txt:str)->list:\n",
        "    \"\"\"\n",
        "    Tokenizes a given text using NLTK's word_tokenize function and filters out non-alphanumeric tokens.\n",
        "\n",
        "    Args:\n",
        "    - txt (str): Input text to tokenize.\n",
        "\n",
        "    Returns:\n",
        "    - list: List of alphanumeric tokens extracted from the text.\n",
        "    \"\"\"\n",
        "    return [x for x in word_tokenize(text=txt,language='english') if x.isalnum()]\n",
        "\n",
        "  def get_token_probabilities(self,stxt:str)->dict:\n",
        "    \"\"\"\n",
        "    Computes the probability of each token in the given text.\n",
        "\n",
        "    Args:\n",
        "    - stxt (str): Input text to analyze.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Dictionary where keys are tokens and values are their probabilities (relative frequencies).\n",
        "      The probability of each token is computed as its count divided by the total number of tokens.\n",
        "    \"\"\"\n",
        "    tokens:List[str] = self.get_nltk_word_tokenize(txt=stxt)\n",
        "    token_counts:Counter[str] = Counter(tokens)\n",
        "    total_count:int = len(tokens)\n",
        "    return {token: count / total_count for token,count in token_counts.items()}\n",
        "\n",
        "  def get_jensen_shannon_divergence(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the Jensen-Shannon divergence between the token probability distributions of two texts.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First text.\n",
        "    - sent_2 (str): Second text.\n",
        "\n",
        "    Returns:\n",
        "    - float: Jensen-Shannon divergence score between the token distributions of the two texts.\n",
        "      The score ranges from 0 (identical distributions) to 1 (completely different distributions).\n",
        "      It measures the similarity between two probability distributions using the Jensen-Shannon divergence metric.\n",
        "    \"\"\"\n",
        "    text_prob_1:dict = self.get_token_probabilities(stxt=sent_1)\n",
        "    text_prob_2:dict = self.get_token_probabilities(stxt=sent_2)\n",
        "    tokens:set = set(text_prob_1.keys()).union(set(text_prob_2.keys()))\n",
        "    text_probs_1:np.ndarray = np.array([text_prob_1.get(token, 0) for token in tokens])\n",
        "    text_probs_2:np.ndarray = np.array([text_prob_2.get(token, 0) for token in tokens])\n",
        "    return 1 - jensenshannon(p=text_probs_1,q=text_probs_2)\n",
        "\n",
        "  def get_ratcliff_obershelp_similarity(self,sent_1:str,sent_2:str)->float:\n",
        "    \"\"\"\n",
        "    Computes the Ratcliff/Obershelp similarity between two strings.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "\n",
        "    Returns:\n",
        "    - float: Ratcliff/Obershelp similarity score between the two strings.\n",
        "      The score ranges from 0 (no similarity) to 1 (exact match),\n",
        "      computed as the length of the longest common subsequence divided by the maximum length of the two strings.\n",
        "    \"\"\"\n",
        "    if not sent_1 or not sent_2:\n",
        "      return 0.0\n",
        "    match_:list = [[0] * (len(sent_2) + 1) for _ in range(len(sent_1) + 1)]\n",
        "    for i in range(1,len(sent_1) + 1):\n",
        "      for j in range(1,len(sent_2) + 1):\n",
        "        if sent_1[i - 1] == sent_2[j - 1]:\n",
        "          match_[i][j] = match_[i - 1][j - 1] + 1\n",
        "        else:\n",
        "          match_[i][j] = max(match_[i][j - 1],match_[i - 1][j])\n",
        "    return match_[len(sent_1)][len(sent_2)] / max(len(sent_1),len(sent_2))\n",
        "\n",
        "  def get_monge_elkan_similarity(self,sent_1:str,sent_2:str,n_pairs:int=2)->float:\n",
        "    \"\"\"\n",
        "    Computes the Monge-Elkan similarity between two strings based on n-gram similarity.\n",
        "\n",
        "    Args:\n",
        "    - sent_1 (str): First string.\n",
        "    - sent_2 (str): Second string.\n",
        "    - n_pairs (int): Number of n-grams to use for similarity comparison (default is 2).\n",
        "\n",
        "    Returns:\n",
        "    - float: Monge-Elkan similarity score between the two strings.\n",
        "      The score ranges from 0 to 1, where higher values indicate greater similarity.\n",
        "      It measures similarity based on the best match of n-grams between the two strings,\n",
        "      using 1 minus the normalized edit distance.\n",
        "    \"\"\"\n",
        "    similarity_total:float = 0.0\n",
        "    text_total_pairs:float = 0.0\n",
        "    for gram_1 in ngrams(sequence=self.get_nltk_word_tokenize(txt=sent_1),n=n_pairs):\n",
        "      best_sim_:float = 0\n",
        "      for gram_2 in ngrams(sequence=self.get_nltk_word_tokenize(txt=sent_2),n=n_pairs):\n",
        "        sim_:float = self.get_editdistance(sent_1=gram_1,sent_2=gram_2)\n",
        "        if sim_ > best_sim_:\n",
        "          best_sim_ = sim_\n",
        "      similarity_total += best_sim_\n",
        "      text_total_pairs += 1\n",
        "    similarity_score:float = (similarity_total / text_total_pairs) if text_total_pairs > 0 else 0.0\n",
        "    return similarity_score\n",
        "\n",
        "  def trim_characters(self,stxt:str='')->str:\n",
        "    \"\"\"\n",
        "    Removes non-alphanumeric characters from a string.\n",
        "\n",
        "    Args:\n",
        "    - stxt (str): Input string.\n",
        "\n",
        "    Returns:\n",
        "    - str: String with non-alphanumeric characters removed.\n",
        "    \"\"\"\n",
        "    return re.compile(pattern=r'\\s+').sub(repl=r' ',string=str(re.compile(pattern=r'[^a-zA-Z\\d]').sub(repl=r' ',string=str(stxt)))).strip()\n",
        "\n",
        "  def create_final_folder(self)->None:\n",
        "    \"\"\"\n",
        "    Creates Output Folder.\n",
        "    If the folder already exists, it is first removed along with all its contents, and then a new empty folder is created.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    if os.path.exists(path=self.output_folder):\n",
        "      # Forcefully delete a directory and its contents\n",
        "      shutil.rmtree(path=self.output_folder)\n",
        "    os.mkdir(path=self.output_folder)\n",
        "    return None\n",
        "\n",
        "  def create_final_zip(self)->None:\n",
        "    \"\"\"\n",
        "    Creates a ZIP archive of all the contents.\n",
        "    This method walks through the directory structure, adds all files to a ZIP archive, and stores it as '.zip'.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    # Creates ZIP\n",
        "    with zipfile.ZipFile(file=self.output_folder+'.zip',mode='w',compression=zipfile.ZIP_DEFLATED) as zip_file:\n",
        "      for all_root,all_dirs,all_files in os.walk(self.output_folder):\n",
        "        for file_1 in all_files:\n",
        "          temp_file_path = os.path.join(all_root,file_1)\n",
        "          zip_file.write(\n",
        "            temp_file_path,\n",
        "            os.path.relpath(temp_file_path,self.output_folder)\n",
        "            )\n",
        "\n",
        "    zip_file_path:str = self.output_folder+'.zip'\n",
        "    target_folder_path:str = self.output_folder\n",
        "    os.rename(os.path.abspath(zip_file_path),os.path.abspath(os.path.join(target_folder_path,zip_file_path)))\n",
        "    return None\n",
        "\n",
        "  def pre_processing_text_values(self,txt:str='',is_lower:bool=True,remove_characters:bool=True)->str:\n",
        "    \"\"\"\n",
        "    Pre-processes text values by lowercasing, removing non-alphanumeric characters, and tokenizing.\n",
        "\n",
        "    Args:\n",
        "    - txt (str): Input text.\n",
        "    - is_lower (bool, optional), default = True: Convert text to lowercase.\n",
        "    - remove_characters (bool, optional), default = True: Remove non-alphanumeric characters.\n",
        "\n",
        "    Returns:\n",
        "    - str: Pre-processed text.\n",
        "    \"\"\"\n",
        "    if is_lower:\n",
        "      txt:str=str(txt).lower().strip()\n",
        "    else:\n",
        "      txt:str=str(txt).strip()\n",
        "\n",
        "    if remove_characters:\n",
        "      txt:str=self.trim_characters(stxt=txt)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    return ' '.join([x for x in word_tokenize(txt) if x.isalnum()])\n",
        "\n",
        "  def get_all_similarity_scores(self,row1:pd.Series)->pd.Series:\n",
        "    \"\"\"\n",
        "    Calculates similarity scores between Doc1 and Doc2 Elements using various metrics.\n",
        "\n",
        "    Args:\n",
        "    - row1 (pd.Series): Input row containing text columns for comparison.\n",
        "\n",
        "    Returns:\n",
        "    - pd.Series: Series with similarity scores appended.\n",
        "    \"\"\"\n",
        "    doc1_,doc2_=row1[self.col_name_1],row1[self.col_name_2]\n",
        "    for metric_name,metric_func in self.scoring_metrics.items():\n",
        "      if metric_name in ['get_minhash_containment_distance']:\n",
        "        row1[metric_name.replace('get_','high_score_')]=round(number=metric_func(sent_1=doc1_,sent_2=doc2_)*100,ndigits=4)\n",
        "      elif metric_name in ['get_monge_elkan_similarity']:\n",
        "        for i in range(1,4):\n",
        "          row1[metric_name.replace('get_','high_score_')+'_'+str(i)]=round(number=metric_func(sent_1=doc1_,sent_2=doc2_,n_pairs=i),ndigits=4)\n",
        "      elif metric_name in [\n",
        "          'get_editdistance',\n",
        "          'get_levenshtein_distance',\n",
        "          'get_damerau_levenshtein_distance',\n",
        "          'get_hamming_distance',\n",
        "          'get_normalized_compression_distance',\n",
        "          'get_difflib_sequencematcher',\n",
        "          'get_minhash_containment_distance',\n",
        "      ]:\n",
        "        row1[metric_name.replace('get_','low_score_')]=round(number=metric_func(sent_1=doc1_,sent_2=doc2_),ndigits=4)\n",
        "      else:\n",
        "        row1[metric_name.replace('get_','high_score_')]=round(number=metric_func(sent_1=doc1_,sent_2=doc2_),ndigits=4)\n",
        "    return row1\n",
        "\n",
        "  def main(self)->None:\n",
        "    \"\"\"\n",
        "    Main function to perform text scoring and write results to a CSV file.\n",
        "    \"\"\"\n",
        "    start_time:float = time.time()\n",
        "\n",
        "    self.create_final_folder()\n",
        "\n",
        "    # single core processing\n",
        "    # self.df1:pd.DataFrame = self.df1.apply(lambda x: self.get_all_similarity_scores(row1=x),axis=1)\n",
        "\n",
        "    # using pandarallel for multiprocessing\n",
        "    self.df1:pd.DataFrame = self.df1.parallel_apply(lambda x: self.get_all_similarity_scores(row1=x),axis=1)\n",
        "\n",
        "    self.df1.to_csv(path_or_buf=self.output_folder+'/Similarity_Scores.csv',index=False,mode='w',encoding='utf-8') # save in CSV file format\n",
        "    # self.create_final_zip()\n",
        "    print(f\"Elapsed time: {((time.time() - start_time) / 60):.2f} minutes\")\n",
        "    return None\n",
        "\n",
        "def custom_ram_cleanup_func()->None:\n",
        "  \"\"\"\n",
        "  Clean up global variables except for specific exclusions and system modules.\n",
        "\n",
        "  This function deletes all global variables except those specified in\n",
        "  `exclude_vars` and variables starting with underscore ('_').\n",
        "\n",
        "  Excluded variables:\n",
        "  - Modules imported into the system (except 'sys' and 'os')\n",
        "  - 'sys', 'os', and 'custom_ram_cleanup_func' itself\n",
        "\n",
        "  Returns:\n",
        "  None\n",
        "  \"\"\"\n",
        "\n",
        "  import sys\n",
        "  all_vars = list(globals().keys())\n",
        "  exclude_vars = list(sys.modules.keys())\n",
        "  exclude_vars.extend(['In','Out','_','__','___','__builtin__','__builtins__','__doc__','__loader__','__name__','__package__','__spec__','_dh','_i','_i1','_ih','_ii','_iii','_oh','exit','get_ipython','quit','sys','os','custom_ram_cleanup_func',])\n",
        "  for var in all_vars:\n",
        "      if var not in exclude_vars and not var.startswith('_'):\n",
        "          del globals()[var]\n",
        "  del sys\n",
        "  return None\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  import pandas as pd\n",
        "\n",
        "  # Sample DataFrame\n",
        "  df = pd.DataFrame(data={\n",
        "      'doc1_elements': ['apple', 'banana', 'cherry'],\n",
        "      'doc2_elements': ['apples', 'bannnana', 'charries']\n",
        "  })\n",
        "\n",
        "  # Create TextScoring instance and compute similarity scores\n",
        "  TextScoring(\n",
        "      dataframe_object=df,\n",
        "      output_folder='Example2',\n",
        "      col_name_1='doc1_elements',\n",
        "      col_name_2='doc2_elements',\n",
        "      metrics_list=['fuzz_token_set_ratio', 'jaro_winkler_similarity']\n",
        "  ).main()\n",
        "\n",
        "  custom_ram_cleanup_func()\n",
        "  del custom_ram_cleanup_func"
      ],
      "metadata": {
        "id": "WNcC3I26mN_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43b27b7-62fa-46ee-c8e2-3bed4d655bb2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for importlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "All required packages are installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Pandarallel will run on 1 workers.\n",
            "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
            "All required packages are imported.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample DataFrame\n",
        "df = pd.DataFrame(data={\n",
        "    'doc1_elements': ['apple', 'banana', 'cherry'],\n",
        "    'doc2_elements': ['apples', 'bannnana', 'charries'],\n",
        "})\n",
        "\n",
        "# Create TextScoring instance and compute similarity scores\n",
        "TextScoring(\n",
        "    dataframe_object=df,\n",
        "    output_folder='Example2',\n",
        "    col_name_1='doc1_elements',\n",
        "    col_name_2='doc2_elements',\n",
        "    metrics_list=['fuzz_token_set_ratio', 'jaro_winkler_similarity']\n",
        ").main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "97e9e04ba281444ea591f5cc5e81ab3f",
            "a444ccbc20a94ce8ae2d21a670d1d0ac",
            "54fd809f37c04e8a8a8200caf79a1b2d",
            "7be0938036294567b0333a25d78848b5",
            "40847630145246fa94d8dfbfe4dde862",
            "10409517e0cd4f38a2f91d9501e480b2",
            "c29e9ea662e4411d8af5789b6d36d6fc",
            "4a6c1f40273c4f33a45689a59f4536ac",
            "4b2e17593c9e4de4a019a9d503eda458",
            "5d8bc4ceeb32476b8073053c8c120b03"
          ]
        },
        "id": "arqxGT7X5WBg",
        "outputId": "50622fd3-bc85-46ce-edb8-adb485bb7321"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3), Label(value='0 / 3'))),))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97e9e04ba281444ea591f5cc5e81ab3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 0.00 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lsh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGmm1Xed5aoh",
        "outputId": "78a79f57-f78b-4ee2-cb43-7408f16eceb3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8.0K\n",
            "4.0K drwxr-xr-x 2 root root 4.0K Jul 10 23:17 Example2\n",
            "4.0K drwxr-xr-x 1 root root 4.0K Jul  9 13:21 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('./Example2/Similarity_Scores.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "G6WAM1FG5vfx",
        "outputId": "ebd983f0-3597-4702-9991-31033ce24817"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  doc1_elements doc2_elements  high_score_fuzz_token_set_ratio  \\\n",
              "0         apple        apples                               91   \n",
              "1        banana      bannnana                               86   \n",
              "2        cherry      charries                               57   \n",
              "\n",
              "   high_score_jaro_winkler_similarity  \n",
              "0                             96.6667  \n",
              "1                             90.2778  \n",
              "2                             77.7778  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f22a7d8f-8836-4ffb-b629-818074f59825\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc1_elements</th>\n",
              "      <th>doc2_elements</th>\n",
              "      <th>high_score_fuzz_token_set_ratio</th>\n",
              "      <th>high_score_jaro_winkler_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>apple</td>\n",
              "      <td>apples</td>\n",
              "      <td>91</td>\n",
              "      <td>96.6667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>banana</td>\n",
              "      <td>bannnana</td>\n",
              "      <td>86</td>\n",
              "      <td>90.2778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cherry</td>\n",
              "      <td>charries</td>\n",
              "      <td>57</td>\n",
              "      <td>77.7778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f22a7d8f-8836-4ffb-b629-818074f59825')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f22a7d8f-8836-4ffb-b629-818074f59825 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f22a7d8f-8836-4ffb-b629-818074f59825');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d489e12e-04fe-4623-82b4-eae11b744465\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d489e12e-04fe-4623-82b4-eae11b744465')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d489e12e-04fe-4623-82b4-eae11b744465 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"doc1_elements\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"apple\",\n          \"banana\",\n          \"cherry\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doc2_elements\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"apples\",\n          \"bannnana\",\n          \"charries\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high_score_fuzz_token_set_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 57,\n        \"max\": 91,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          91,\n          86,\n          57\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high_score_jaro_winkler_similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.607797062976163,\n        \"min\": 77.7778,\n        \"max\": 96.6667,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          96.6667,\n          90.2778,\n          77.7778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_ram_cleanup_func()\n",
        "del custom_ram_cleanup_func"
      ],
      "metadata": {
        "id": "6h8A3mW4mUbo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UUih61zf8AXI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97e9e04ba281444ea591f5cc5e81ab3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a444ccbc20a94ce8ae2d21a670d1d0ac"
            ],
            "layout": "IPY_MODEL_54fd809f37c04e8a8a8200caf79a1b2d"
          }
        },
        "a444ccbc20a94ce8ae2d21a670d1d0ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7be0938036294567b0333a25d78848b5",
              "IPY_MODEL_40847630145246fa94d8dfbfe4dde862"
            ],
            "layout": "IPY_MODEL_10409517e0cd4f38a2f91d9501e480b2"
          }
        },
        "54fd809f37c04e8a8a8200caf79a1b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be0938036294567b0333a25d78848b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100.00%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c29e9ea662e4411d8af5789b6d36d6fc",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a6c1f40273c4f33a45689a59f4536ac",
            "value": 3
          }
        },
        "40847630145246fa94d8dfbfe4dde862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b2e17593c9e4de4a019a9d503eda458",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5d8bc4ceeb32476b8073053c8c120b03",
            "value": "3 / 3"
          }
        },
        "10409517e0cd4f38a2f91d9501e480b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c29e9ea662e4411d8af5789b6d36d6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a6c1f40273c4f33a45689a59f4536ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b2e17593c9e4de4a019a9d503eda458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d8bc4ceeb32476b8073053c8c120b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}